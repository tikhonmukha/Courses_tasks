{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5343d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f8137e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('russian_poetry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b072e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date_from</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Михаил Лермонтов</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>Забывши волнения жизни мятежной,\\r\\nОдин жил в...</td>\n",
       "      <td>Забывши волнения жизни мятежной...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Сергей Есенин</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>Нивы сжаты, рощи голы,\\r\\nОт воды туман и сыро...</td>\n",
       "      <td>Нивы сжаты, рощи голы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Игорь Северянин</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>Лючинь печальная читала вечером ручьисто-вкрад...</td>\n",
       "      <td>ЧАРЫ ЛЮЧИНЬ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Анатолий Жигулин</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>Глыбу кварца разбили молотом,\\r\\nИ, веселым ог...</td>\n",
       "      <td>Золото</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Николай Тихонов</td>\n",
       "      <td>1937.0</td>\n",
       "      <td>Хлынул дождь, когда девушки, встав в хоровод,\\...</td>\n",
       "      <td>Хоровод в Сульдуси</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author  date_from  \\\n",
       "0  Михаил Лермонтов     1829.0   \n",
       "1     Сергей Есенин     1917.0   \n",
       "2   Игорь Северянин     1919.0   \n",
       "3  Анатолий Жигулин     1963.0   \n",
       "4   Николай Тихонов     1937.0   \n",
       "\n",
       "                                                text  \\\n",
       "0  Забывши волнения жизни мятежной,\\r\\nОдин жил в...   \n",
       "1  Нивы сжаты, рощи голы,\\r\\nОт воды туман и сыро...   \n",
       "2  Лючинь печальная читала вечером ручьисто-вкрад...   \n",
       "3  Глыбу кварца разбили молотом,\\r\\nИ, веселым ог...   \n",
       "4  Хлынул дождь, когда девушки, встав в хоровод,\\...   \n",
       "\n",
       "                                 name  \n",
       "0  Забывши волнения жизни мятежной...  \n",
       "1            Нивы сжаты, рощи голы...  \n",
       "2                         ЧАРЫ ЛЮЧИНЬ  \n",
       "3                              Золото  \n",
       "4                  Хоровод в Сульдуси  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78c6d988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16694 entries, 0 to 16693\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   author     16694 non-null  object \n",
      " 1   date_from  12857 non-null  float64\n",
      " 2   text       16694 non-null  object \n",
      " 3   name       16182 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 521.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ca15268",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].replace(r'[^\\w\\s]',' ',regex=True).replace(r'\\s+',' ',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf726b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Забывши волнения жизни мятежной \r\n",
      "Один жил в пустыне рыбак молодой \r\n",
      "Однажды на скале прибрежной \r\n",
      "Над тихой прозрачной рекой\r\n",
      "Он с удой беспечно\r\n",
      "Сидел\r\n",
      "И думой сердечной\r\n",
      "К прошедшему счастью летел \n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0,'text_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d736b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bd616be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as spacy\n",
    "from spacy import load\n",
    "from spacy.lang.ru.examples import sentences\n",
    "from spacy.lang.ru import Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e29af17",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = spacy.load('ru_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e82c01b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m post \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m load_model\u001b[38;5;241m.\u001b[39mpipe(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_clean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39ments:\n\u001b[0;32m      4\u001b[0m         post\u001b[38;5;241m.\u001b[39mappend(entity\u001b[38;5;241m.\u001b[39mlabel_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\spacy\\language.py:1618\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[1;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[0;32m   1616\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m pipes:\n\u001b[0;32m   1617\u001b[0m         docs \u001b[38;5;241m=\u001b[39m pipe(docs)\n\u001b[1;32m-> 1618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m doc\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\spacy\\util.py:1685\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[0;32m   1676\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1677\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeCallable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m   1683\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1685\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1687\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:245\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\spacy\\util.py:1632\u001b[0m, in \u001b[0;36mminibatch\u001b[1;34m(items, size)\u001b[0m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1631\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[1;32m-> 1632\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1634\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\spacy\\util.py:1685\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[0;32m   1676\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1677\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeCallable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m   1683\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1684\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1685\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1687\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\spacy\\pipeline\\pipe.pyx:57\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:135\u001b[0m, in \u001b[0;36mLemmatizer.__call__\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc:\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverwrite \u001b[38;5;129;01mor\u001b[39;00m token\u001b[38;5;241m.\u001b[39mlemma \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 135\u001b[0m             token\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\spacy\\lang\\ru\\lemmatizer.py:133\u001b[0m, in \u001b[0;36mRussianLemmatizer.pymorphy3_lemmatize\u001b[1;34m(self, token)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpymorphy3_lemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, token: Token) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pymorphy_lemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\spacy\\lang\\ru\\lemmatizer.py:62\u001b[0m, in \u001b[0;36mRussianLemmatizer._pymorphy_lemmatize\u001b[1;34m(self, token)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [PUNCT_RULES\u001b[38;5;241m.\u001b[39mget(string, string)]\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m univ_pos \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADJ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDET\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOUN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNUM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRON\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROPN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVERB\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pymorphy_lookup_lemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m analyses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_morph\u001b[38;5;241m.\u001b[39mparse(string)\n\u001b[0;32m     64\u001b[0m filtered_analyses \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\spacy\\lang\\ru\\lemmatizer.py:118\u001b[0m, in \u001b[0;36mRussianLemmatizer._pymorphy_lookup_lemmatize\u001b[1;34m(self, token)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pymorphy_lookup_lemmatize\u001b[39m(\u001b[38;5;28mself\u001b[39m, token: Token) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    117\u001b[0m     string \u001b[38;5;241m=\u001b[39m token\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m--> 118\u001b[0m     analyses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_morph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# often multiple forms would derive from the same normal form\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# thus check _unique_ normal forms\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     normal_forms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([an\u001b[38;5;241m.\u001b[39mnormal_form \u001b[38;5;28;01mfor\u001b[39;00m an \u001b[38;5;129;01min\u001b[39;00m analyses])\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\pymorphy3\\analyzer.py:321\u001b[0m, in \u001b[0;36mMorphAnalyzer.parse\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprob_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 321\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprob_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_to_parses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_lower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\pymorphy3\\analyzer.py:77\u001b[0m, in \u001b[0;36mProbabilityEstimator.apply_to_parses\u001b[1;34m(self, word, word_lower, parses)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parses:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parses\n\u001b[1;32m---> 77\u001b[0m probs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_t_given_w\u001b[38;5;241m.\u001b[39mprob(word_lower, tag)\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (word, tag, normal_form, score, methods_stack) \u001b[38;5;129;01min\u001b[39;00m parses]\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(probs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# no P(t|w) information is available; return normalized estimate\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mmap\u001b[39m(_score_getter, parses))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\pymorphy3\\analyzer.py:77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parses:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parses\n\u001b[1;32m---> 77\u001b[0m probs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_t_given_w\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_lower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (word, tag, normal_form, score, methods_stack) \u001b[38;5;129;01min\u001b[39;00m parses]\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(probs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# no P(t|w) information is available; return normalized estimate\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mmap\u001b[39m(_score_getter, parses))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\pymorphy3\\dawg.py:66\u001b[0m, in \u001b[0;36mConditionalProbDistDAWG.prob\u001b[1;34m(self, word, tag)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprob\u001b[39m(\u001b[38;5;28mself\u001b[39m, word, tag):\n\u001b[0;32m     65\u001b[0m     dawg_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (word, tag)\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdawg_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMULTIPLIER\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\dawg_python\\dawgs.py:453\u001b[0m, in \u001b[0;36mIntDAWG.get\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m    452\u001b[0m     key \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 453\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m LOOKUP_ERROR:\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\dawg_python\\dawgs.py:459\u001b[0m, in \u001b[0;36mIntDAWG.b_get_value\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mb_get_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m--> 459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\dawg_python\\wrapper.py:44\u001b[0m, in \u001b[0;36mDictionary.find\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExact matching (returns value)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 44\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mROOT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\dawg_python\\wrapper.py:64\u001b[0m, in \u001b[0;36mDictionary.follow_bytes\u001b[1;34m(self, s, index)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFollows transitions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m s:\n\u001b[1;32m---> 64\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_char\u001b[49m\u001b[43m(\u001b[49m\u001b[43mint_from_byte\u001b[49m\u001b[43m(\u001b[49m\u001b[43mch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\dawg_python\\wrapper.py:53\u001b[0m, in \u001b[0;36mDictionary.follow_char\u001b[1;34m(self, label, index)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfollow_char\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, index):\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFollows a transition\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 53\u001b[0m     offset \u001b[38;5;241m=\u001b[39m \u001b[43munits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_units\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     next_index \u001b[38;5;241m=\u001b[39m (index \u001b[38;5;241m^\u001b[39m offset \u001b[38;5;241m^\u001b[39m label) \u001b[38;5;241m&\u001b[39m units\u001b[38;5;241m.\u001b[39mPRECISION_MASK\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m units\u001b[38;5;241m.\u001b[39mlabel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_units[next_index]) \u001b[38;5;241m!=\u001b[39m label:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\dawg_python\\units.py:30\u001b[0m, in \u001b[0;36moffset\u001b[1;34m(base)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Read a label with a leaf flag from a non-leaf unit. \"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base \u001b[38;5;241m&\u001b[39m _mask\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moffset\u001b[39m(base):\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Read an offset to child units from a non-leaf unit. \"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ((base \u001b[38;5;241m>>\u001b[39m \u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m<<\u001b[39m ((base \u001b[38;5;241m&\u001b[39m EXTENSION_BIT) \u001b[38;5;241m>>\u001b[39m \u001b[38;5;241m6\u001b[39m)) \u001b[38;5;241m&\u001b[39m PRECISION_MASK\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "post = []\n",
    "for doc in load_model.pipe(df['text_clean'].values):\n",
    "    for entity in doc.ents:\n",
    "        post.append(entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2768670d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dostoevsky'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdostoevsky\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegexTokenizer\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdostoevsky\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastTextSocialNetworkModel\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dostoevsky'"
     ]
    }
   ],
   "source": [
    "from dostoevsky.tokenization import RegexTokenizer\n",
    "from dostoevsky.models import FastTextSocialNetworkModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5554719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dostoevsky"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [33 lines of output]\n",
      "  C:\\Users\\Muha.Tihon\\AppData\\Local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages\\setuptools\\dist.py:745: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Usage of dash-separated 'description-file' will not be supported in future\n",
      "          versions. Please use the underscore name 'description_file' instead.\n",
      "  \n",
      "          This deprecation is overdue, please update your project and remove deprecated\n",
      "          calls to avoid build errors in the future.\n",
      "  \n",
      "          See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    opt = self.warn_dash_deprecation(opt, section)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-310\n",
      "  creating build\\lib.win-amd64-cpython-310\\fasttext\n",
      "  copying python\\fasttext_module\\fasttext\\FastText.py -> build\\lib.win-amd64-cpython-310\\fasttext\n",
      "  copying python\\fasttext_module\\fasttext\\__init__.py -> build\\lib.win-amd64-cpython-310\\fasttext\n",
      "  creating build\\lib.win-amd64-cpython-310\\fasttext\\util\n",
      "  copying python\\fasttext_module\\fasttext\\util\\util.py -> build\\lib.win-amd64-cpython-310\\fasttext\\util\n",
      "  copying python\\fasttext_module\\fasttext\\util\\__init__.py -> build\\lib.win-amd64-cpython-310\\fasttext\\util\n",
      "  creating build\\lib.win-amd64-cpython-310\\fasttext\\tests\n",
      "  copying python\\fasttext_module\\fasttext\\tests\\test_configurations.py -> build\\lib.win-amd64-cpython-310\\fasttext\\tests\n",
      "  copying python\\fasttext_module\\fasttext\\tests\\test_script.py -> build\\lib.win-amd64-cpython-310\\fasttext\\tests\n",
      "  copying python\\fasttext_module\\fasttext\\tests\\__init__.py -> build\\lib.win-amd64-cpython-310\\fasttext\\tests\n",
      "  running build_ext\n",
      "  building 'fasttext_pybind' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for fasttext\n",
      "ERROR: Could not build wheels for fasttext, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached dostoevsky-0.6.0-py2.py3-none-any.whl (8.5 kB)\n",
      "Collecting fasttext==0.9.2 (from dostoevsky)\n",
      "  Using cached fasttext-0.9.2.tar.gz (68 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting razdel==0.5.0 (from dostoevsky)\n",
      "  Using cached razdel-0.5.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: pybind11>=2.2 in c:\\users\\muha.tihon\\appdata\\local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages (from fasttext==0.9.2->dostoevsky) (2.11.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\muha.tihon\\appdata\\local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages (from fasttext==0.9.2->dostoevsky) (68.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\muha.tihon\\appdata\\local\\anaconda3\\envs\\r-tutorial\\lib\\site-packages (from fasttext==0.9.2->dostoevsky) (1.26.1)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py): started\n",
      "  Building wheel for fasttext (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for fasttext\n",
      "Failed to build fasttext\n"
     ]
    }
   ],
   "source": [
    "!pip install dostoevsky"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
